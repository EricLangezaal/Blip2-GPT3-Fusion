{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_api_key = \"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\"\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_chat_gpt(prompt, max_tokens=64, temperature=0.7, stop=None):\n",
    "  \"\"\"\n",
    "  Helper function for prompting the GPT3 chat-based language model\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":  \"You are a helpful assistant that generates questions that extract visual information\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Someone asked you '{prompt}'. List the three best distinct questions you would like to be answered \\\n",
    "         by a visual information retrieval system, such that you can best answer '{prompt}'. Only list questions that can be answered \\\n",
    "            without modifying the image. I want only the distinct questions, don't say anything else.\"}\n",
    "        ],\n",
    "    max_tokens = 150,\n",
    "    temperature=temperature)\n",
    "\n",
    "  return response[\"choices\"][0]['message'][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the size and shape of the item?\n",
      "2. In what location or environment is the item typically found?\n",
      "3. What other objects or features are present in the image that could indicate the type of vehicle?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What sort of vehicle uses this item?\"\n",
    "gpt_questions = prompt_chat_gpt(prompt)\n",
    "print(gpt_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the size of the item?',\n",
       " 'What is the shape of the item?',\n",
       " 'What are the features of the item?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_questions = gpt_questions.split('\\n')\n",
    "gpt_questions = [question[3:] for question in gpt_questions]\n",
    "gpt_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
