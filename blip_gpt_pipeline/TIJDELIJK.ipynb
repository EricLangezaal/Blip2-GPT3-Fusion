{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "\n",
    "openai_api_key = \"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\"\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_chat_gpt(prompt, max_tokens=64, temperature=0.7, stop=None):\n",
    "  \"\"\"\n",
    "  Helper function for prompting the GPT3 chat-based language model\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":  \"You are a helpful assistant that generates questions that extract visual information\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Someone asked you '{prompt}'. List the three best distinct questions you would like to be answered \\\n",
    "         by a visual information retrieval system, such that you can best answer '{prompt}'. Only list questions that can be answered \\\n",
    "            without modifying the image. I want only the distinct questions, don't say anything else.\"}\n",
    "        ],\n",
    "    max_tokens = 150,\n",
    "    temperature=temperature)\n",
    "\n",
    "  return response[\"choices\"][0]['message'][\"content\"].strip()\n",
    "\n",
    "def gpt_generate_questions(input_questions, temperature=0.7):\n",
    "\n",
    "    gpt_questions = []\n",
    "    for question in input_questions:\n",
    "       questions = prompt_chat_gpt(question, temperature=temperature)\n",
    "       questions = questions.split('\\n')\n",
    "       questions = [prompt_question(re.search(\"[a-zA-Z].*\", question).group()) for question in questions]\n",
    "       gpt_questions.append(questions)\n",
    "       \n",
    "    return gpt_questions\n",
    "\n",
    "def prompt_question(questions):\n",
    "    if isinstance(questions, list):\n",
    "      return [f\"Question: {q} Short answer:\" for q in questions]\n",
    "    return f\"Question: {questions} Short answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What type of engine is visible in the image?\n",
      "2. What is the shape of the item?\n",
      "3. Are any wheels or tires visible in the image?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What sort of vehicle uses this item?\"\n",
    "gpt_questions = prompt_chat_gpt(prompt)\n",
    "print(gpt_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the size of the item?',\n",
       " 'What is the shape of the item?',\n",
       " 'What are the features of the item?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_questions = gpt_questions.split('\\n')\n",
    "gpt_questions = [question[3:] for question in gpt_questions]\n",
    "gpt_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What type of engine is visible in the image?',\n",
       " 'What is the shape of the item?',\n",
       " 'Are any wheels or tires visible in the image?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_questions = gpt_questions.split('\\n')\n",
    "gpt_questions = [re.search(\"[a-zA-Z].*\", question).group() for question in gpt_questions]\n",
    "gpt_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarized_gpt(questions, answers, original_question, original_answer, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Helper function for prompting the GPT3 chat-based language model\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":  \"You are truthful assistant that gives an answer to an original question. You can utilise the information from multiple partial questions that have been answered.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The main question is '{original_question}'. The original answer form the visual question answering \\\n",
    "         model was '{original_answer}'\"}\n",
    "        ]\n",
    "    \n",
    "    for question, answer in zip(questions, answers):\n",
    "       messages.append({\"role\": \"user\", \"content\": f\"We asked: {question}\"})\n",
    "       messages.append({\"role\": \"user\", \"content\": f\"The answer: {answer}\"})\n",
    "\n",
    "    messages.extend([{\"role\": \"user\", \"content\": f\"Please answer the original question: '{original_question}'. You can either repeat the original answer '{original_answer}', or improve it if necessary. Give the shortest answer possible, in only a few words.\"}])\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=messages,\n",
    "      max_tokens = 150,\n",
    "      temperature=temperature)\n",
    "\n",
    "    return response[\"choices\"][0]['message'][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_gpt(gpt_questions, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
